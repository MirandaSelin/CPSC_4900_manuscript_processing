# Manuscript Processing Pipeline Configuration
# 
# This file specifies all paths and parameters for the four-stage pipeline:
# 1. manuscript_segmentation.py - Run Kraken segmentation (requires kraken-env)
# 2. glyph_extraction.py - Extract glyphs from manuscript images
# 3. glyph_embedder.py - Generate deep learning embeddings for glyphs
# 4. glyph_similarity_search.py - Find similar glyphs
#
# Copy this template and fill in your paths:
#   cp template_config.ini my_manuscript_config.ini
#
# Then run the pipeline:
#   python manuscript_segmentation.py my_manuscript_config.ini  (requires kraken-env)
#   python glyph_extraction.py my_manuscript_config.ini
#   python glyph_embedder.py my_manuscript_config.ini
#   python glyph_similarity_search.py my_manuscript_config.ini

[paths]
# Path to manuscript TIFF image
tiff_file = /path/to/manuscript.tiff

# Path to ALTO XML segmentation file (from Kraken OCR)
xml_file = /path/to/segmentation.xml

# Directory for extracted glyphs and metadata
# Will contain: glyphs/ subdirectory and glyph_metadata.csv
components_dir = /path/to/output/components

# Directory for embeddings and enhanced metadata
# Will contain: glyph_embeddings.npz and glyph_metadata_with_embeddings.csv
embeddings_dir = /path/to/output/embeddings

# Directory for visualization outputs (similarity search grids, etc)
visualizations_dir = /path/to/output/visualizations

[extraction]
# Minimum glyph area in pixels (filters out noise/small artifacts)
# Default: 20
min_area = 20

# Maximum glyph area in pixels (filters out merged text/large artifacts)
# Default: 5000
max_area = 5000

# Padding around glyph bounding boxes in pixels
# Default: 5
padding = 5

[embeddings]
# Embedding model to use
# Options: hog, resnet50, trocr
# - hog: Traditional computer vision (fast, good for character recognition)
# - resnet50: Deep learning on natural images (slower, may not work well for text)
# - trocr: Transformer trained on handwritten text (best for manuscripts, slowest)
# Default: hog
model = hog

# Target size for image processing
# - hog: 64 recommended
# - resnet50/trocr: 224 or 384
# Default: 64
target_size = 64

# Batch size for processing glyphs (only used for deep learning models)
# Higher = faster but uses more memory (try 8, 16, 32, or 64)
# Default: 8
batch_size = 8

[search]
# Glyph ID to search for (e.g., glyph_000001)
# Leave empty to skip similarity search
query_glyph_id = 

# Number of similar glyphs to return
# Default: 10
top_k = 10

# Whether to generate visualization grid
# Default: true
generate_visualization = true

# Size of thumbnail images in visualization grids
# Default: 100
thumbnail_size = 100
